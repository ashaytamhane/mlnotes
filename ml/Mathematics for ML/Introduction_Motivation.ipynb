{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction & Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are three main concepts at the core\n",
    "  - Data: Vector (we will assume converted into suitable numerical form)\n",
    "  - Model: Typically used to describe the process for generating the data. Good models can be thought of simplified versions of real (unknown) generating process. Good model can be used to predict what would happen in real-world without performing real-world experiments. We choose a model either using probabilistic or optimization view\n",
    "  - Learning: Assume we are given a dataset and a model. Training the model means to the available data to optimise some parameters of the model with respect to a utility function that evaluates how well the model predicts the training data. Most training methods can be thought of as an approach to hill climbing. Peak of the hill corresponds to max of desired performance measure. In practice we are interested in model to perform well on unseen data in order to generalise well. We learn from available data by using numerical optimization methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part I\n",
    "* We represent numerical data as vectors and table of such data as matrix. Study of vectors and matrices is called linear algebra (Chapter 2)\n",
    "* Given two vectors representing two objects in real world, we want to make statements about their similarity. Vectors that are similar should be predicted to have similar outputs my the ML algorithm (predictor). To formalise idea of similarity, we need analytic geometry (Chapter 3)\n",
    "* Some operations on matrices are extremely useful in ML. They allow for more intuitive interpretation of data and efficient learning (Chapter 4)\n",
    "* Data is often considered noisy representation of some true underlying signal. We hope ML can help us identify signal from the noise. However, in order to have a language for quantifying \"noise\" and to express uncertainty in predictors, we need probability theory (Chapter 6)\n",
    "* To train ML models, we typically find parameters that max performance metrics. Many optimisation techniques require gradient, which tells us the direction in which to search for a solution. This needs vector calculus (Chapter 5), which will be used in optimisation to find maxima/minima of functions (Chapter 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part II\n",
    " * This part introduces four pillars of ML - Regression, Dimensionality reduction, density estimation and Classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

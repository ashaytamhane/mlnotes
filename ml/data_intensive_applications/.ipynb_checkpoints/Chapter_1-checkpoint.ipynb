{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliable, Scalable and Maintainable Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three fundmanetal concerns with most systems:\n",
    "* Reliability - Tolerating hardware & software faults, human error\n",
    "* Scalability - Measuring load & performance, Latency percentiles/throughput\n",
    "* Maintainability - Operability, simplicity & evolvability\n",
    "\n",
    "Amount, complexity and speed of data leads to most problems in today's applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Standard Building Blocks for most applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Databases** - Store data so that it can be found again\n",
    "* **Caches** - Remeber the result of an expensive operation, to speed up reads\n",
    "* **Search indexes** - Search or filter data based on keywords\n",
    "* **Stream processing** - Asynchronous handling of messages\n",
    "* **Batch processing** - Periodical crunching of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single building block/tool is typically not enough to build an application. Often we need to break down the problem into multiple tasks/tools and stitched together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing to work correctly, even when things go wrong\n",
    "* Application performs the function that user expects\n",
    "* Tolerate user mistakes or unexpected flows\n",
    "* Good performance under expected load and data volume \n",
    "* Prevents unauthorised access/abuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fault is not the same as Failure**\n",
    "\n",
    "* Fault is typically one component deviating from spec, but failure is when entire system stops providing service to user\n",
    "* It is hard to avoid faults, therefore it is best to design fault-tolerant mechanisms that prevent faults from causing failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harware Faults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When you have a lot of machines in large datacenters, probability of hardware faults is high\n",
    "* This could be because of hard disk crash, RAM errors, power grid backouts or human errors\n",
    "* RAID - We add redundant components so that when one component dies, other can take over\n",
    "* Software fault-tolerance techniques are preferred or used in addition to hardware redundancy due to operational advantages since they support rolling upgrades (one node at a time) instead of downtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Faults\n",
    "* Harware faults are typically random and independent from each other (one machine failing may not imply other will fail)\n",
    "* A different class of faults is a systematic error which are harder to anticipate as co-relation is across nodes. Examples:\n",
    "  * A software bug that crashes application server for some bad input\n",
    "  * A runaway process that uses up a shared resource (CPU time, memory, disk space, network bandwidth)\n",
    "  * A service that system depends on slows down/becomes unresponsive or sends corrupted responses\n",
    "  * Cascading failures where one component triggers fault in another fault"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How do we make systems reliable, inspite of unreliable humans designing/building software and running them?\n",
    "  * Design systems in a way that minimises opportunity for error - well designed abstractions, APIs, and admin interfaces\n",
    "  * Provide sandbox environments where people can explore and experiment safely using real data without impact real users\n",
    "  * Rogorous testing from unit testing to whole system integration tests including corner cases\n",
    "  * Easy recovery from human errors - enable fast roll back configuration changes or code\n",
    "  * Detailed, clear monitoring - performance metrics and error rates (called as telemetry in other engg disciplines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Even if a system is working reliably today, it may not necessarily mean that it will continue to do so in future\n",
    "* This could be because of increased load in number of users or data volume\n",
    "* Scalability is the term we use to describe a system's ability to cope with increased load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We define load with a few numbers referred to as load parameters\n",
    "\n",
    "* Best choice of parameters depends on the architecture of system. Examples:\n",
    "  * Requests per second (web server)\n",
    "  * Ratio of reads to writes (database)\n",
    "  * Number of concurrent users (chatroom)\n",
    "  * Hit rate (cache)\n",
    "  * Avg case vs extreme case of parameters depends on the use case\n",
    "\n",
    "\n",
    "* Twitter example (2012 data)\n",
    "    * Posting a tweet - User can publish a tweet to their followers, which results in 4.6k requests per second on avg and 12k requests at peak\n",
    "    * Home timeline - User can view tweets posted by people they follow (300k requests per sec)\n",
    "    * Here the main challenge is *fanout* , each user follows many people and each user is followed by many people. The term fanout is borrowed from electronic engineering where it describes the number of logic gate inputs that are attached to another gate's output. Output needs to supply enough current to drive all out attached inputs. In transaction processing systems, we use it to describe the number of requests to other services that we need to make in order to serve one incoming request\n",
    "    * This fanout is handled by Twitter by computing results ahead of time and storing in timeline caches\n",
    "    * Hybrid approach (pulling tweets on the fly+pre computing and storing) is used where users with large fan following are dealt with caching where as most users continue to be fanned out. This helps reduce the number of writes in the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Two ways to look at load:\n",
    "    * When we increase a load parameter and keep the system resources unchanged, how is the system performance impacted?\n",
    "    * When we increase a load parameter, how much do we need to increase resources to keep performance unchanged?\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defining performance\n",
    "  * In a batch processing system, we generally care about throughput - Number of records we can process per second, or total time it takes to run a job on dataset of certain size. In an ideal world the running time of a batch job is size of dataset divided by the throughput. In practice, the running time is often longer due to skew in data (data not being spread across worker processes uniformly) and needing to wait for slowest task to compelete\n",
    "  * In online systems, whats more important is the response time - Time between a client sending a request and receiving a response. Latency is NOT the same as response time. Response time is what the client sees - it includes network delays + queueing delays apart from the service or processing time. Latency is purely the duration that a request is waiting to be handled during which it is latent (awaiting service)\n",
    "  * Even if we make the same request over and over again, we will get slightly different response time. Therefore we need to think of response time as a distribution of values, not just a single number. Median and higher percentiles are typically good metrics to measure outliers/how many requests are impacted (instead of just using mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches for coping with load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scaling up - Vertical scaling or moving to a more powerful machine\n",
    "* Scaling out - Horizontal scaling or distributing load across multiple smaller machines. This is also called as shared nothing architecture\n",
    "* Good architectures are generally a pragamatic mixture of both - using several fairly powerful machines can be simpler and cheaper than a large number of small virtual machines\n",
    "* Some systems are elastic - can automatically add computing resources when they detect increase in load. This is useful when load is unpredictable. For predictable loads, manually scaled systems are simpler and do not come with operational surprises (partition rebalancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is well known that most of the cost of software is not in initial development, but in its ongoing maintenance - fixing bugs, keeping its systems operational, investigating failures, adapting it to new platforms, modifying it for new cases, repaying tech debt, adding new features\n",
    "* To enable better maintainability of systems, we use three design principles:\n",
    "  * Operability - Make it easy for operations teams to keep the systems running smoothly\n",
    "  * Simplicity - Make it easy for new engineers to understand the system, by removing as much complexity as possible from system\n",
    "  * Evolvability - Make it eays for engineers to make changes to the system in future, adapting it for unanticipated use cases as requirements change. Also known as extensibility, mofifiability or plasticity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding and Evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Applications change over time. Evolvability aims to build systems that make it easy to adapt to change\n",
    "* In most cases, change to application's features also requires change to data leading to code changes\n",
    "* Relational dbs assume a fixed schema at any point in time, where as schema-on-read dbs don't enforce a schema\n",
    "* Server side applications could do rolling upgrade (staged rollout) where we deploy new version on few nodes at a time\n",
    "* Client side applications rely on users to install the update\n",
    "* Forward and backward compatibility is required for smooth running of systems\n",
    "* We will look at several formats for encoding data - how they handle schema changes and used for storage and communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formats for Encoding Data**\n",
    " * Programs work with data in two different representations:\n",
    "   - In memory, data is kept in objects, structs, lists, arrays etc\n",
    "   - Data is written to a file and sent over network as a self-contained sequence of bytes\n",
    " * We need some translation between these two representations. Such translation from in-memory representation to byte sequence is called encoding or serialization or marshalling. Reverse is called decoding (parsing, deserialization, unmarshalling)\n",
    " * There are many libraries and formats to choose from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Language-specific formats**\n",
    " * Programming languages typically have a built-in support for encoding\n",
    " * Ex: Java has java.io.Serializable, Python has pickle. Such libraries are convenient because they allow in-memory objects to be saved and restored with minimal additional code. However, they have a number of problems:\n",
    "   - Encoding is tied to specific programming language and reading in another language is difficult. This implies we also commit to a programming language for a long time \n",
    "   - Since decoding needs to instantiate arbitrary classes, this has security issues and could be exploited to run arbitrary code\n",
    " * Therefore, it is typically a bad idea to use language's built-in encoding except for temporary needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON, XML, Binary Variants**\n",
    " * JSON and XML are obvious contenders for standardised encodings that can be written/read across languages\n",
    " * XML is often criticized for being too verbose/unnecessarily complex\n",
    " * JSON is popular due to simplicity and built in support for web browser. CSV is also popular, but less powerful\n",
    " * JSON, XML and CSV are all textual and somewhat human readable. However they have issues\n",
    "   - Ambiguity around encoding numbers. XML and CSV have no way to distinguish between a number and string consisting of digits. JSON distinguishes between strings and numbers, but not integers and floating-point numbers (and no precision). This is a problem when deadling with lage numbers\n",
    "   - JSON/XML have good support for unicode character strings, but don't support binary strings. As a work around, people encode binary data as text, but this increases the data size \n",
    "   - Schema usage is optional for XML/JSON. Applications that don't use schema potentially hardcode the encoding/decoding logic\n",
    "   - CSV does not have schema and depends on applications to define meaning of row/column. It is also vague in terms of interpretation of comma or newline as value\n",
    " * Despite these flaws, all these three formats are good enough for many purposes. Especially for data interchange formats (sending data from one org to another), it is more important to agree on format than efficiency - here JSON/XML/CSV scores well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Binary Encoding****\n",
    " * For data to be consumed internal to org, we can focus on encoding that is more compact or faster to parse\n",
    " * Both JSON/XML use a lot of space compared to binary formats. This led to development of binary encodings for JSON(MessagePack, BSON, BJSON, BISON, etc) and for XML (WBXML, Fast infoset). However none of them are as widely adopted as text version of JSON and XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Thrift and Protocol Buffers****\n",
    " * Apache Thrift and Protocol Buffer (protobuf) are binary encoding libraries (thrift was originally developed at Facebook and protobuf at Google)\n",
    " * Both of these require schema for encoding\n",
    " * Avro is another encoding where there is a writer's schema and a reader's schema. Key idea here is that writer and reader schema don't have to be same, but rather compatible (each schema has a version). Avro library resolves differences by looking at the two schemas side by side and translating from writer's schema to reader's.\n",
    " * Avro does not have any field tag numbers as opposed to Protobuf or thrift. This is useful for dynamically generated schemas (ex: table has column added and one removed) as a new Avro schema can be generated. In protobuf or thrift, thie would need a manual reassignment of field tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Modes of Dataflow****\n",
    " * A few common ways of how data flows between processes:\n",
    "   - Via Databases\n",
    "   - Via Service Calls\n",
    "   - Via Asynchronous message passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Dataflow Through Databases****\n",
    " * In database, process that writes data in db encodes it and the process that reads from db decodes it\n",
    " * At times, this is a single process that both encodes and decodes. However there could be multiple processes accessing at same time as well. These processes might be from different applications, some running newer code and some older versions. Therefore both backward and forward compatibility is required.\n",
    " * Schema evolution allows entire db to appear as if it was encoded in single schema, even though underlying storage may contain records encoded with various historical versions of the schema (ex: Linkedin document db uses Avro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Dataflow Through Services****\n",
    " * Common arrangement for processes to communicate over network is client and server\n",
    " * The API exposed via server is called as a service\n",
    " * On web: clients (web browsers) make requests to web servers, making GET requests to download HTML/CSS, JS, images etc and making POST requests to submit data to server. Since the API consists of standardized set of protocols and data formats (HTTP, URLs, SSL/TLS, HTML, etc), in theory you can use any web browser to access any website\n",
    " * Native app running on mobile device or desktop computer is another client. Client-side JS application running inside a web browser can use XMLHttpRequest to become a HTTP client (called as Ajax)\n",
    " * Server itself can be a client to another service (web app server acting as a client to a db)\n",
    " * This approach is often used to decompose a large application into smaller services by functionality. This has been traditionally called service oriented architecture (SOA) and recently rebranded as microservices architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Web Services****\n",
    " * When HTTP is used as the protocol for talking to service, it is called a web service\n",
    " * There are two popular approaches to web services: REST and SOAP\n",
    " * REST is not a protocol, but a design philosophy that builds on principles of HTTP. Fross cross-org service integration, REST is more popular \n",
    " * SOAP is an XML based protocol for making network API requests, based on WSDL (web services description language) which is not human readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problems with RPC (remote procedure calls)**\n",
    " * RPC essentially tries to make remote network service similar to a local call within programming language (call in the same process). Although this seems convenient at first, this approach is fundamentally flawed as network request is very different from a local function call\n",
    " * Local function call is predictable (fails or succeeds depending on local parameters). Network request is unpredictable due to multiple parameters outside our control : network problem, remote machine issue\n",
    " * Network request may timeout, in which case we don't really know what happened (request go through or not)\n",
    " * If requests are getting through and responses are lost, it could result in same action performed multiple times unless a dedup mechanism is in place (idempotence)\n",
    " * Remote calls have unpredictable latencies and payloads could be an issue with larger objects\n",
    " * Client and service may be implemented in different languages, which could create issues to translate datatypes from one language to other\n",
    " * REST is more appealing as it does not try to hide the fact that local and remote calls are fundamentally different\n",
    " * Main focus of RPC frameworks is requests between services owned by same org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Message-Passing Dataflow**\n",
    " * We look at asynchronous message passing which are somewhere between RPC and databases\n",
    " * Similarity with RPC - client request (usually called message) is delivered to another process with low latency\n",
    " * Similarity with Db - message is not sent via direct network connection, but via message broker (message queue)\n",
    " * Using message broker has advantages over direct RPC:\n",
    "   * Can act as buffer when recipient is unavailable or loaded\n",
    "   * Can redeliver messages to process that has crashed\n",
    "   * Avoids sender needing to know IP/port of recipient (especially useful in cloud where vms can change)\n",
    "   * One message can be sent to multiple recipients\n",
    "   * Logically decouples sender from recipient (sender doesn't care who consumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Message Brokers**\n",
    " * RabbitMQ, ActiveMQ, Apache Kafka are some of the open source implementations of message brokers\n",
    " * A process sends message to named queue or topic, and broker ensures that message is delivered to one or more consumers of or subscribers to that queue or topic. There can be many producers and many consumers on the same topic\n",
    " * Topic is a one-way dataflow, however consumer themselves may publish messages to another topic\n",
    " * Message brokers dont enforce any encoding format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distributed actor frameworks**\n",
    " * Actor model is a programming model for concurrency in a single process\n",
    " * Rather than dealing directly with threads (and deadling with the associated problems of race condition, locking etc), logic is encapsulated in actors\n",
    " * Each actor typically represents one client or entity, it may have some local state which is not shared. One actor communicates with other actors using asynch messages\n",
    " * In distributed actor frameworks, this model is used to scale application across nodes\n",
    " * Distributed actor framework integrates message broker and actor programming model into a single framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
